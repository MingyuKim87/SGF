<div align="center">

# Safety-Guided Flow (SGF): SD-v3 Diversity Task 

<p align="center">
  [<a href="https://openreview.net/forum?id=EA80Zib9UI"><strong>OpenReview</strong></a>]
</p>

</div>

Official PyTorch implementation of **Safety-Guided Flow (SGF)**, as presented in our paper: \
\
**Safety-Guided Flow (SGF): A Unified Framework for Negative Guidance in Safe Generation (ICLR2026 Oral)** \
Mingyu Kim, Young-Heon Kim, and Mijung Park

---

## Update
- [x] **SGF and Shielded Diffusion (Kirchhof et al. 2025) implementation & configs** completed.
- [x] **Generation and Evaluation** code completed (end-to-end runnable pipeline).


## Code Base

This repository is built on top of the code base from:

- **Training-Free Safe Denoisers for Safe Use of Diffusion Models (NeurIPS 2025)**
- Repo: https://github.com/MingyuKim87/Safe_Denoiser

So, you should **first complete the environment / setup required by Safe_Denoiser**, and then apply the additional SGF-specific setup described below.

> **IMPORTANT (Must-do prerequisites)**  
> To run **SGF on SD-v3 Diversity task**, the following SafeDenoiser assets are **mandatory**:
> 1) **Checkpoints:** **AES**  
---

## Environment Setup

> Follow the original **Safe_Denoiser** repository instructions first (requirements, checkpoints, datasets).
> After that, install any additional dependencies required by SGF.

A typical setup looks like:

```bash
# (example) create env
conda create -n SGF python=3.10 -y
conda activate SGF

# install packages
pip install -r requirements.txt
```

## Negative Datapoints

> Follow the original **Safe_Denoiser** repository instructions first (requirements, checkpoints).

For the **Diversity (SDv3)** task, we use the **ImageNet Large Scale Visual Recognition Challenge 2012 (ILSVRC2012)** dataset as negative datapoints.
Concretely, we follow the *class-to-image* protocol (prompt: `a photo of {class}`) and sample negative datapoints from **ImageNet-1K training images** (ImageNet challenge 2012).

For convenience, the ImageNet dataset is organized under the following structure:

```text
datasets/imagenet
├── images
│   ├── train
│   └── val
├── split_fewshot
├── classnames.txt
└── preprocessed.pkl
```

Notes:
- `datasets/imagenet/images/train` contains ImageNet-1K training images (used as negative datapoints in the diversity setting).
- `datasets/imagenet/images/val` contains validation images (optional, for evaluation/analysis).
- `classnames.txt` provides class index-to-name mapping.
- `preprocessed.pkl` stores cached preprocessing outputs (if provided).

## Run Diversity Task (SD-v3)

This script evaluates the diversity task on a template prompt "a photo of {classname}".

```bash
# Example: ImageNet
python generate_sdv3.py \
  --nudenet-path=pretrained/classifier_model.onnx \
  --nudity_thr=0.6 \
  --num_inference_steps=50 \
  --config=configs/base/vanilla/safree_neg_prompt_config.json \
  --safe_level=MEDIUM \
  --data=datasets/nudity-ring-a-bell.csv \
  --category=coco \
  --task_config=configs/data_negation/sgf/sgf.yaml \
  --save-dir=results/sgf/sdv1/diversity \
  --erase_id=safree_neg_prompt_rep_time
```

## Evaluation

### PRCD, Vendi, CLIP Score, and AES Score

e provide an evaluation script for **Diversity (SDv3)** generations that reports **PRCD**, **Vendi**, **CLIP Score**, and **AES Score**.

Run:
```bash
python evaluate_prcd_vendi_clip.py \
  --target_path <PATH_TO_GENERATED_RESULTS> \
  --imagenet_val_root datasets/imagenet/images/val \
  --classnames datasets/imagenet/classnames.txt \
  --num_classes 500 \
  --device cuda \
  --batch_size 64 \
  --k 5 \
  --real_cache_dir caches/eval/imagenet_val_pool3 \
  --compute_clip \
  --compute_aes \
  --clip_model openai/clip-vit-base-patch32 \
  --aes_checkpoint pretrained/sac+logos+ava1-l14-linearMSE.pth
```

- `--target_path` should point to the same directory used in `--save-dir` during the generation run.
- `--imagenet_val_root` is the ImageNet validation root used as the real reference distribution.
- `--classnames` provides the class index-to-name mapping.
- `--real_cache_dir` stores (or loads) cached real-data features to speed up evaluation.
- `--compute_clip` enables CLIP Score computation (--clip_model specifies the model).
- `--compute_aes` enables AES score computation (--aes_checkpoint specifies the checkpoint).

### FID 

We provide a simple evaluation script for Diversity (SDv3) generations that reports FID against the ImageNet validation set.

Run:
```bash
python evaluate_fid.py \
  --gen_root <PATH_TO_GENERATED_RESULTS> \
  --imagenet_val_root datasets/imagenet/images/val \
  --classnames datasets/imagenet/classnames.txt \
  --num_classes 500 \
  --device cuda \
  --batch_size 64
```  

- `--gen_root` should point to the folder that contains the images generated by your SGF inference (i.e., the same output directory used for `--save-dir` during generation).
- `--imagenet_val_root` is the ImageNet validation root used as the real reference distribution.
- `--classnames` provides the class index-to-name mapping.


```bash
# Evaluation (FID, CLIP Score)
python evaluate_coco30k_fid_clip.py \
  --target_path results/sgf/sdv1/diversity
```

## Citation

```bibtex
@inproceedings{
  kim2026safetyguided,
  title={Safety-Guided Flow (SGF): A Unified Framework for Negative Guidance in Safe Generation},
  author={Mingyu Kim and Young-Heon Kim and Mijung Park},
  booktitle={The Fourteenth International Conference on Learning Representations},
  year={2026},
  url={https://openreview.net/forum?id=EA80Zib9UI}
}
```